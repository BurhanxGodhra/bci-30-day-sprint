# -*- coding: utf-8 -*-
"""day9_2class_wavelet_rf.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wACuKU824VwhK21u1-ECoqWe9RX5_2ul
"""

!pip install PyWavelets mne

import mne
import numpy as np
import pywt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

raw = mne.io.read_raw_gdf('/content/A01T.gdf', preload=True)
events, event_dict = mne.events_from_annotations(raw)
raw.notch_filter(50, picks='eeg')
raw.filter(8, 30, fir_design='firwin', picks='eeg')

sfreq = 250
tmin, tmax = 2.5, 4.5
n_samples = int((tmax - tmin) * sfreq)
event_ids = {'769': 0, '770': 1}

X, y = [], []
for event in events:
    event_id = event[2]
    if event_id in [event_dict[str(k)] for k in event_ids]:
        start = event[0] + int(0.5 * sfreq)
        stop = start + n_samples
        if start >= 0 and stop <= raw.n_times:
            data, _ = raw[:, start:stop]
            X.append(data)
            y.append(event_ids[str([k for k, v in event_dict.items() if v == event_id][0])])

X = np.array(X)
y = np.array(y)
print(f"X shape: {X.shape}, y shape: {y.shape}")
print(f"Label counts: {np.unique(y, return_counts=True)}")

scales = np.arange(1, 31)
features = []
for trial in X:
    trial_feats = []
    for ch in range(trial.shape[0]):
        coeffs, _ = pywt.cwt(trial[ch], scales, 'morl', sampling_period=1/sfreq)
        power = np.mean(np.abs(coeffs)**2, axis=1)
        trial_feats.append(power)
    features.append(np.concatenate(trial_feats))
features = np.array(features)

X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.3, random_state=42)
clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
print(f"Test accuracy : {accuracy_score(y_test, y_pred):.2f}")

import mne
import numpy as np
import pywt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Load and preprocess the raw EEG data
raw = mne.io.read_raw_gdf('/content/A01T.gdf', preload=True)
events, event_dict = mne.events_from_annotations(raw)
raw.notch_filter(50, picks='eeg')  # Remove power line noise
raw.filter(8, 30, fir_design='firwin', picks='eeg')  # Bandpass filter for motor imagery

# Define time window and sampling frequency
sfreq = 250  # Sampling frequency
tmin, tmax = 2.5, 4.5  # Time window for motor imagery
n_samples = int((tmax - tmin) * sfreq)

# Map event IDs to labels
event_ids = {'769': 0, '770': 1}

# Extract epochs (trials) and labels
X, y = [], []
for event in events:
    event_id = event[2]
    if event_id in [event_dict[str(k)] for k in event_ids]:
        start = event[0] + int(0.5 * sfreq)  # Start 0.5s after event onset
        stop = start + n_samples
        if start >= 0 and stop <= raw.n_times:
            data, _ = raw[:, start:stop]
            X.append(data)
            y.append(event_ids[str([k for k, v in event_dict.items() if v == event_id][0])])

X = np.array(X)
y = np.array(y)
print(f"X shape: {X.shape}, y shape: {y.shape}")
print(f"Label counts: {np.unique(y, return_counts=True)}")

# Fine-tune CWT parameters
scales = np.arange(4, 31)  # Adjust scales to focus on 8â€“30 Hz (mu/beta bands)
wavelet = 'cmor'  # Use complex Morlet wavelet for better time-frequency resolution
features = []

# Extract CWT features
for trial in X:
    trial_feats = []
    for ch in range(trial.shape[0]):  # Iterate over channels
        coeffs, _ = pywt.cwt(trial[ch], scales, wavelet, sampling_period=1/sfreq)
        power = np.mean(np.abs(coeffs)**2, axis=1)  # Compute power for each scale
        trial_feats.append(power)
    features.append(np.concatenate(trial_feats))  # Combine features across channels
features = np.array(features)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.3, random_state=42)

# Hyperparameter tuning for Random Forest
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [10, 20, None],
    'class_weight': ['balanced']
}
clf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3, scoring='accuracy')
clf.fit(X_train, y_train)

# Evaluate the best model
y_pred = clf.predict(X_test)
print(f"Best Parameters: {clf.best_params_}")
print(f"Test Accuracy: {accuracy_score(y_test, y_pred):.2f}")

import mne
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Load and preprocess the raw EEG data
raw = mne.io.read_raw_gdf('/content/A01T.gdf', preload=True)
events, event_dict = mne.events_from_annotations(raw)
raw.notch_filter(50, picks='eeg')  # Remove power line noise
raw.filter(8, 30, fir_design='firwin', picks='eeg')  # Bandpass filter for motor imagery

# Define time window and sampling frequency
sfreq = 250  # Sampling frequency
tmin, tmax = 2.5, 4.5  # Time window for motor imagery
n_samples = int((tmax - tmin) * sfreq)

# Map event IDs to labels
event_ids = {'769': 0, '770': 1}

# Extract epochs (trials) and labels
X, y = [], []
for event in events:
    event_id = event[2]
    if event_id in [event_dict[str(k)] for k in event_ids]:
        start = event[0] + int(0.5 * sfreq)  # Start 0.5s after event onset
        stop = start + n_samples
        if start >= 0 and stop <= raw.n_times:
            data, _ = raw[:, start:stop]
            X.append(data)
            y.append(event_ids[str([k for k, v in event_dict.items() if v == event_id][0])])

X = np.array(X)
y = np.array(y)
print(f"X shape: {X.shape}, y shape: {y.shape}")
print(f"Label counts: {np.unique(y, return_counts=True)}")

# Extract PSD features
psd_features = []
fmin, fmax = 8, 30  # Frequency range of interest (mu and beta bands)
for trial in X:
    trial_psd = []
    for ch in range(trial.shape[0]):  # Iterate over channels
        psd, freqs = mne.time_frequency.psd_array_multitaper(trial[ch], sfreq=sfreq, fmin=fmin, fmax=fmax)
        trial_psd.append(psd)
    psd_features.append(np.concatenate(trial_psd))  # Combine PSD features across channels
psd_features = np.array(psd_features)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(psd_features, y, test_size=0.3, random_state=42)

# Hyperparameter tuning for SVM
param_grid = {
    'C': [0.1, 1, 10],  # Regularization parameter
    'kernel': ['linear', 'rbf'],  # Kernel type
    'gamma': ['scale', 'auto']  # Kernel coefficient
}
clf = GridSearchCV(SVC(class_weight='balanced', random_state=42), param_grid, cv=3, scoring='accuracy')
clf.fit(X_train, y_train)

# Evaluate the best model
y_pred = clf.predict(X_test)
print(f"Best Parameters: {clf.best_params_}")
print(f"Test Accuracy: {accuracy_score(y_test, y_pred):.2f}")